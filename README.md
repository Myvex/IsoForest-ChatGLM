# 原理说明

## 一、背景与目标  
- **日志数据**：系统、应用、网络等产生的海量文本日志，包含时间戳、级别、模块、错误码、堆栈信息等。  
- **问题**：从成千上万条日志中快速定位真正的“错误”或“异常”事件，避免人工“海量筛查”。  
- **方案**：  
  1. **Isolation Forest**（孤立森林）对日志进行无监督异常检测，找出“可疑”日志条目。  
  2. **ChatGLM**（大语言模型）将检测到的异常信息转化为易读的自然语言报告，供运维或业务人员快速理解与响应。  

下面按步骤拆解原理与实现细节。

---

## 二、Isolation Forest 处理日志的原理

### 1. Isolation Forest 简介  
- **核心思想**：异常点更容易被“孤立”。  
- **算法流程**  
  1. 随机选取特征与阈值，构造二叉树。  
  2. 对于每条样本，记录其在树中被切分的深度。  
  3. 树深度越浅，表示该样本越容易被孤立 → 越可能是异常。  
- **优点**  
  - 适合高维数据。  
  - 训练、预测时间低。  
  - 只需一个超参数 `contamination`（异常比例）即可控制阈值。  

### 2. 日志 → 结构化特征  
日志本身是文本，需先转化为数值特征才能喂给 Isolation Forest。常见做法：

| 维度 | 说明 | 典型实现 |
|------|------|----------|
| **时间特征** | 解析时间戳，提取年、月、日、小时、分钟、秒、周几等 | `datetime` |
| **级别特征** | `ERROR`、`WARN`、`INFO` 等 | One‑Hot 或 Label 编码 |
| **模块/服务** | 产生日志的模块或服务名 | One‑Hot / Embedding |
| **错误码 / 关键词** | 关键字、错误码 | TF‑IDF、词袋、BERT 等 |
| **日志长度** | 字符数 | 直接数值 |
| **堆栈信息** | 是否包含堆栈 | 0/1 |
| **频率特征** | 该条日志在最近 N 秒内出现的次数 | 计数 |

> **技巧**  
> - 对文本特征做 **embedding**（如 `sentence‑embedding`、`LogBERT` 等）能捕获语义相似性。  
> - 对高维稀疏特征做 **PCA / TruncatedSVD** 降维，减少噪声。  

### 3. 训练与检测  
1. **训练**  
   - 先把日志按“正常”与“异常”标签分离（如果有标签）。  
   - 也可以直接用全量日志训练，设定 `contamination=0.01`（假设 1% 为异常）。  
   - `IsolationForest(n_estimators=200, max_samples='auto', contamination=0.01, random_state=42)`  
2. **预测**  
   - `model.decision_function(X)` → 异常分数（越小越异常）。  
   - `model.predict(X)` → 1（正常）/ -1（异常）。  
3. **阈值调优**  
   - 通过 ROC、PR 曲线或业务指标（误报率/漏报率）微调 `contamination` 或直接设定分数阈值。  

### 4. 结果筛选  
- 取分数最高（或最低）的前 N 条日志。  
- 对同一错误类型做聚类（如 DBSCAN、KMeans）进一步归类。  
- 统计每类错误出现次数、时间分布、关联模块等，生成 **异常摘要表**。  

---

## 三、ChatGLM 输出自然语言报告的原理

### 1. ChatGLM 简介  
- **大语言模型**，支持中文生成、对话、摘要等。  
- 通过 **Prompt Engineering**（提示工程）可让模型把结构化数据转化为人类可读的文本。  

### 2. 报告生成流程  

| 步骤 | 内容 | 关键技术 |
|------|------|----------|
| **1. 结构化输入** | 异常日志列表 + 统计表（错误码、次数、时间段、关联模块等） | JSON / YAML |
| **2. Prompt 设计** | `请根据以下数据生成一份运维报告：<数据>` | 设计含义明确、语气专业 |
| **3. 模型推理** | ChatGLM 接收 Prompt，生成自然语言文本 | 生成式推理 |
| **4. 后处理** | 过滤多余信息、统一表述、添加建议 | 正则、模板 |
| **5. 输出** | 发送邮件、写入日志、推送到监控面板 | 业务集成 |

#### 示例 Prompt  
```
请根据以下异常日志摘要生成一份简短的运维报告（约 150 字）：

1. 错误类型: 连接超时
   发生次数: 67 次
   主要模块: 数据库连接池
   发生时间段: 2025-08-27 14:00-15:00

2. 错误类型: 文件读取错误
   发生次数: 23 次
   主要模块: 配置加载
   发生时间段: 2025-08-27 13:45-14:15

请说明异常原因、影响范围，并给出初步排查建议。
```

**ChatGLM 输出示例**  
> 在 2025‑08‑27 14:00‑15:00 期间，数据库连接池出现 67 次“连接超时”错误，导致业务请求延迟。  
> 13:45‑14:15 期间，配置加载模块报 23 次“文件读取错误”，可能是文件权限或磁盘空间不足。  
> 建议：检查数据库服务器 CPU/IO 负载，确认网络链路；检查配置文件路径权限，查看磁盘空间。  

### 3. 进一步增强  
- **Fine‑tuning**：在业务日志摘要上微调 ChatGLM，提升专业术语准确性。  
- **多轮对话**：先让模型生成初稿，再让运维人员通过交互式问答细化报告。  
- **可视化**：将生成的文字与图表（如异常频率折线图）一起展示，形成完整的“异常报告 Dashboard”。  

---

## 四、完整工作流示例

```
┌────────────┐
│ 1. 日志采集 │
└─────┬──────┘
      │
┌─────▼──────┐
│ 2. 预处理 │
│  - 解析时间 │
│  - 过滤非文本 │
│  - 结构化 │
└─────┬──────┘
      │
┌─────▼──────┐
│ 3. 特征化 │
│  - TF‑IDF │
│  - 词向量 │
│  - 统计特征 │
└─────┬──────┘
      │
┌─────▼──────┐
│ 4. Isolation Forest │
│  - 训练 │
│  - 预测 │
│  - 异常列表 │
└─────┬──────┘
      │
┌─────▼──────┐
│ 5. 聚类/统计 │
│  - 归类 │
│  - 计数 │
│  - 时间窗口 │
└─────┬──────┘
      │
┌─────▼──────┐
│ 6. 生成 Prompt │
│  - JSON 结构 │
│  - 语言模板 │
└─────┬──────┘
      │
┌─────▼──────┐
│ 7. ChatGLM │
│  - 生成报告 │
└─────┬──────┘
      │
┌─────▼──────┐
│ 8. 输出/推送 │
│  - 网站 │
│  - 监控面板 │
└────────────┘
```

---


# 命令

python src/main.py logs/system.txt --train --model models/iso_forest.pkl

python src/main.py logs/system.txt --model models/iso_forest.pkl

python src/analyze_rootcause.py --input anomalies.csv --output report.csv
